[
  {
    "objectID": "index.html#introducción",
    "href": "index.html#introducción",
    "title": "Estadística aplicada con R",
    "section": "Introducción",
    "text": "Introducción\n\n\nEs una extensión de la regresión lineal (simple) con la que concluimos el módulo anterior.\nEs usada para predecir una sola variable continua (y) en función de múltiples predictores continuos (un set de variables X).\nTiene prácticamente los mismos supuestos que la regresión lineal simple:\n\nLinearidad de los predictores\nHomogeneidad de la varianza (homocedasticidad)\nIndependencia de los errores (residuos)\nNormalidad de los residuos\nIndependencia de los predictores\n\nUn ejemplo de una regresión múltiple podría expresarse mediante la siguiente ecuación\n\n\n\n\\[\\begin{align}\ny &= \\beta_0 + \\beta_1\\,X_1 + \\beta_2\\,X_2 \\dots \\beta_n\\,X_n\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#pasos-para-una-regresión-múltiple",
    "href": "index.html#pasos-para-una-regresión-múltiple",
    "title": "Estadística aplicada con R",
    "section": "Pasos para una regresión múltiple",
    "text": "Pasos para una regresión múltiple\n\n\nA diferencia de la regresión lineal simple, no existe un proceso estructurado de pasos a seguir en el caso de su extensión a dos o más variables continuas como predictores.\nEl llegar a un modelo apropiado se convierte en lo que algunos estadísticos llaman el “arte de modelar”.\nEn las siguientes diapositivas voy a presentar la manera en que usualmente hago este tipo de modelos y que resumiré en:\n\nEmpezar por lo que se le conoce como un modelo completo (incluyendo todas las variables continuas disponibles).\nRealizar una selección automática de variables sobre el modelo del paso 1.\nChecar manualmente por colinearidad entre las variables del modelo resultante del paso 2.\nRevisar si las variables incluidas tienen sentido (biológico),\nChecar los supuestos de normalidad y homocedasticidad.\nRealizar transformaciones de ser necesario.\nInterpretar resultados.\n\nEstos pasos no representan una sucesión. Dependiendo del problema, quizá ni siquiera sirvan y sus análisis estarán de la mano de más de su buen entendimiento de los datos y los fenómenos que deseen explicar."
  },
  {
    "objectID": "index.html#datos-que-usaremos",
    "href": "index.html#datos-que-usaremos",
    "title": "Estadística aplicada con R",
    "section": "Datos que usaremos",
    "text": "Datos que usaremos\n\n\nUsaremos los datos de rotavirus en Berlin del archivo de Excel “rotXLS.xlsx” que contiene información sobre el conteo de casos de rotavirus en Berlín desde el año 2001 hasta el 2020.\nSupongámos que queremos modelar la variable cases en función de todas las variables metereológicas a nuestra disposición. Para esto, recordemos la descripción de esta tabla de datos\n\n\n\n\n\ndate: fecha de cierre de la toma de datos\ncases: número de casos de rotavirus en la semana\nweek: semana epidemiológica\nincidence: número de casos/100000 habitantes\nFM: media diaria de velocidad del viento (m/s)\nRSK: media diaria de lluvia (mm)\n\n\n\nSHK_TAG: media diaria de nieve (cm)\nPM: media diaria de presión atmosférica (hPa)\nTMK: media diaria de temperatura (°C)\nTXK: media diaria de temperatura máxima (°C)\nTNK: media diaria de temperatura mínima (°C)\nUPM: media diaria de humedad relativa (%)\n\n\n\n\n\nSin embargo, antes de continuar, debemos hacer un preprocesamiento de datos ya que en la estructura original de estos se considera un efecto temporal dado por los años. Para simplificarlo, agruparemos los datos por meses y semanas epidemiológicas."
  },
  {
    "objectID": "index.html#preprocesamiento-de-datos",
    "href": "index.html#preprocesamiento-de-datos",
    "title": "Estadística aplicada con R",
    "section": "Preprocesamiento de datos",
    "text": "Preprocesamiento de datos\n\n\nAsegúrate de tener instaladas las librerías dplyr y lubridate antes de correr este código\n\n\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(lubridate)\nrot_berlin &lt;- read_excel(\"rotXLS.xlsx\")\nrot_berlin$month &lt;- month(rot_berlin$date)\nrot_berlin &lt;- rot_berlin %&gt;%\n  group_by(month, week) %&gt;%\n  summarise(incidence = mean(incidence),\n            cases = round(mean(cases),0),\n            FM = mean(FM),\n            RSK = mean(RSK),\n            SHK_TAG = mean(SHK_TAG),\n            PM = mean(PM),\n            TMK = mean(TMK),\n            TXK = mean(TXK),\n            TNK = mean(TNK),\n            UPM = mean(UPM))\nrot_berlin$month &lt;- as.factor(rot_berlin$month)\nrot_berlin$week &lt;- as.factor(rot_berlin$week)"
  },
  {
    "objectID": "index.html#modelo-completo",
    "href": "index.html#modelo-completo",
    "title": "Estadística aplicada con R",
    "section": "Modelo completo",
    "text": "Modelo completo\n\n\nEmpezaremos formulando un modelo completo para estos datos de la siguiente manera:\n\n\nlm1 &lt;- lm(cases ~ FM + RSK + SHK_TAG + PM + TMK + TXK + TNK + UPM, data = rot_berlin)\n\n\n\nEn la función lm se pueden incluir términos de órdenes superiores (interacciones, cuadrados, cubos, etc) con variables continuas.\nPor simplicidad, únicamente consideraremos predictores de primer orden.\nAdemás que para modelos no lineales es mejor usar funciones adecuadas (lm estima los parámetros usando el algoritmo de máxima probabilidad y puede simplemente no servir)."
  },
  {
    "objectID": "index.html#selección-de-variables",
    "href": "index.html#selección-de-variables",
    "title": "Estadística aplicada con R",
    "section": "Selección de variables",
    "text": "Selección de variables\n\n\nLa selección automática de variables funciona con un algoritmo relativamente sencillo:\n\nRetira una variable a la vez del modelo, calcula un criterio de comparación y repite el proceso\nUsa ese criterio de comparación con respecto a un modelo nulo (sin ningún predictor) y devuelve el modelo que haya obtenido la mejor valoración.\n\nEl criterio de evaluación más usado para comparar modelos es el denominado criterio de información de Akaike (AIC), y es un estimador del error de predicción. Mientras menos sea el valor de AIC, mejores las predicciones que un modelo teoricamente será capaz de realizar.\nRealizamos la selección de variables antes de cualquier diagnóstico o transformación ya que a veces estas últimas “exageran” la importancia de las variables en el caso de hacer la selección después.\nLa manera más sencilla de hacer una selección de variables es usando la función base de R step\n\n\n\n\nstep(lm1)"
  },
  {
    "objectID": "index.html#selección-de-variables-1",
    "href": "index.html#selección-de-variables-1",
    "title": "Estadística aplicada con R",
    "section": "Selección de variables",
    "text": "Selección de variables\n\nstep(lm1)\n\nStart:  AIC=372.26\ncases ~ FM + RSK + SHK_TAG + PM + TMK + TXK + TNK + UPM\n\n          Df Sum of Sq   RSS    AIC\n- TNK      1       2.8 15135 370.27\n- RSK      1      18.7 15151 370.34\n- SHK_TAG  1      42.4 15175 370.44\n&lt;none&gt;                 15132 372.26\n- FM       1     658.0 15790 373.03\n- TMK      1     830.7 15963 373.74\n- PM       1     887.1 16019 373.97\n- TXK      1    1259.3 16392 375.46\n- UPM      1    3660.8 18793 384.35\n\nStep:  AIC=370.27\ncases ~ FM + RSK + SHK_TAG + PM + TMK + TXK + UPM\n\n          Df Sum of Sq   RSS    AIC\n- RSK      1      17.7 15153 368.35\n- SHK_TAG  1      60.8 15196 368.53\n&lt;none&gt;                 15135 370.27\n- FM       1     697.7 15833 371.20\n- PM       1     889.7 16025 371.99\n- TXK      1    1888.5 17024 375.92\n- TMK      1    4107.8 19243 383.88\n- UPM      1    5612.2 20747 388.78\n\nStep:  AIC=368.35\ncases ~ FM + SHK_TAG + PM + TMK + TXK + UPM\n\n          Df Sum of Sq   RSS    AIC\n- SHK_TAG  1      57.9 15211 366.60\n&lt;none&gt;                 15153 368.35\n- FM       1     683.9 15837 369.22\n- PM       1     926.0 16079 370.21\n- TXK      1    2063.6 17216 374.65\n- TMK      1    4347.8 19501 382.75\n- UPM      1    5962.0 21115 387.92\n\nStep:  AIC=366.6\ncases ~ FM + PM + TMK + TXK + UPM\n\n       Df Sum of Sq   RSS    AIC\n&lt;none&gt;              15211 366.60\n- FM    1     698.0 15909 367.51\n- PM    1    1160.5 16371 369.38\n- TXK   1    2076.5 17287 372.92\n- TMK   1    4423.5 19634 381.19\n- UPM   1    5958.9 21169 386.09\n\n\n\nCall:\nlm(formula = cases ~ FM + PM + TMK + TXK + UPM, data = rot_berlin)\n\nCoefficients:\n(Intercept)           FM           PM          TMK          TXK          UPM  \n   2503.898       -7.526       -2.219      -19.360       12.304       -2.425"
  },
  {
    "objectID": "index.html#multicolinearidad",
    "href": "index.html#multicolinearidad",
    "title": "Estadística aplicada con R",
    "section": "Multicolinearidad",
    "text": "Multicolinearidad\n\n\nDe acuerdo a la selección automática, nuestro modelo sería hasta el momento:\n\n\ncases ~ FM + PM + TMK + TXK + UPM\n\n\n\nNingún método de selección de variables automático es perfecto.\nEn este caso, aunque obvio, sabemos que las variables TMK y TXK deben estar correlacionadas al ser medidas de temperatura correspondientes al mismo día.\nBien podríamos deshechar una de las dos, pero cuando no sabemos la naturaleza de las variables, es mejor llevar a cabo un análisis de correlación antes de checar el modelo por sus supuestos.\nEn el módulo de AED ya hicimos una primera aproximación con las matrices de dispersión. Sin embargo, en ellas solo vimos el coeficiente de correlación junto al código de significancia.\nPara estar seguros de que eliminaremos variables correctamente, es mejor dar un vistazo a las matrices de correlación directamente."
  },
  {
    "objectID": "index.html#matrices-de-correlación",
    "href": "index.html#matrices-de-correlación",
    "title": "Estadística aplicada con R",
    "section": "Matrices de correlación",
    "text": "Matrices de correlación\n\n\nPara calcular la matriz de correlación de un conjunto de datos usaremos la librería Hmisc\n\n\n\n\nlibrary(Hmisc)\nmatriz &lt;- rcorr(as.matrix(rot_berlin[,c(5, 8, 9, 10, 12)]))\nmatriz\n\n       FM    PM   TMK   TXK   UPM\nFM   1.00 -0.38 -0.67 -0.66  0.22\nPM  -0.38  1.00  0.14  0.14 -0.02\nTMK -0.67  0.14  1.00  1.00 -0.65\nTXK -0.66  0.14  1.00  1.00 -0.70\nUPM  0.22 -0.02 -0.65 -0.70  1.00\n\nn= 65 \n\n\nP\n    FM     PM     TMK    TXK    UPM   \nFM         0.0019 0.0000 0.0000 0.0824\nPM  0.0019        0.2768 0.2771 0.8562\nTMK 0.0000 0.2768        0.0000 0.0000\nTXK 0.0000 0.2771 0.0000        0.0000\nUPM 0.0824 0.8562 0.0000 0.0000       \n\n\n\n\n\nEn este paso, recomiendo el mirar por fuera de la diagonal y eliminar del análisis una variable de cualquier par que tenga un coeficiente de correlación exactamente igual a 1. En este caso, eliminaré TMK"
  },
  {
    "objectID": "index.html#tiene-todo-esto-sentido",
    "href": "index.html#tiene-todo-esto-sentido",
    "title": "Estadística aplicada con R",
    "section": "¿Tiene todo esto sentido?",
    "text": "¿Tiene todo esto sentido?\n\nHasta aquí, nuestro modelo candidato sería el siguiente\n\n\n\ncases ~ FM + PM + TXK + UPM\n\n\n\nLos algoritmos usados aplican criterios estadísticos, no biológicos (o generalizando, del problema en cuestión)\nConsiderando que el rotavirus se contagia principalmente por contacto directo o indirecto con heces fecales de alguien infectado ¿tiene sentido mantener las variables FM (velocidad media diaria del viento) y PM (presión atmosférica media diaria) como parte del modelo?\nPersonalmente, pienso que no. Para mí, el modelo candidato sería el siguiente\n\n\n\n\n\nlm2 &lt;- lm(cases ~ TXK + UPM, data = rot_berlin)"
  },
  {
    "objectID": "index.html#diagnósticos-de-la-regresión-múltiple",
    "href": "index.html#diagnósticos-de-la-regresión-múltiple",
    "title": "Estadística aplicada con R",
    "section": "Diagnósticos de la regresión múltiple",
    "text": "Diagnósticos de la regresión múltiple\n\n\nUna vez que tengo definido mi modelo candidato lo pondré a prueba de los supuestos:\n\n\n\n\nlm2 &lt;- lm(cases ~ TXK + UPM, data = rot_berlin)\n\n\n\nVamos a introducir otra librería muy útil cuando nos encontramos ante modelos de múltiples variables: performance.\nperformance nos ofrece la posibilidad de chequear dos diagnósticos adicionales:\n\nLa predicción del modelo (basándose en una aproximación Bayesiana)\nLa colinearidad\n\nTambién se lo puede utilizar para modelos univariables (como la regresión lineal).\n\n\n\n\n\nlibrary(performance)\ncheck_model(lm2)"
  },
  {
    "objectID": "index.html#diagnósticos-de-la-regresión-múltiple-1",
    "href": "index.html#diagnósticos-de-la-regresión-múltiple-1",
    "title": "Estadística aplicada con R",
    "section": "Diagnósticos de la regresión múltiple",
    "text": "Diagnósticos de la regresión múltiple"
  },
  {
    "objectID": "index.html#diagnósticos-de-la-regresión-múltiple-2",
    "href": "index.html#diagnósticos-de-la-regresión-múltiple-2",
    "title": "Estadística aplicada con R",
    "section": "Diagnósticos de la regresión múltiple",
    "text": "Diagnósticos de la regresión múltiple\n\n\n\n\n\n\n\n\nChequeo de la predicción posterior\nEste gráfico contrapone la densidad de la distribución de la variable de respuesta con las densidades de las predicciones obtenidas del modelo mediante un proceso de sampleo Bayesiano (por eso apreciamos varias líneas azules). Nos da una idea de qué tan adecuado es nuestro modelo para predecir los valores observados. Idealmente estas dos deberían superponerse."
  },
  {
    "objectID": "index.html#diagnósticos-de-la-regresión-múltiple-3",
    "href": "index.html#diagnósticos-de-la-regresión-múltiple-3",
    "title": "Estadística aplicada con R",
    "section": "Diagnósticos de la regresión múltiple",
    "text": "Diagnósticos de la regresión múltiple\n\n\n\n\n\n\n\n\nChequeo de la colinearidad\nAquí vemos distribuidas en el eje X cada una de las variables que estamos usando como predictores mientras que en el eje Y tenemos el factor de inflación de la varianza (VIF) que cada una de estas contribuye al modelo. Nos da una idea de que variables podríamos eliminar basados en mantener únicamente variables independientes entre sí como predictores."
  },
  {
    "objectID": "index.html#transformaciones",
    "href": "index.html#transformaciones",
    "title": "Estadística aplicada con R",
    "section": "Transformaciones",
    "text": "Transformaciones\n\n\nDel gráfico de la predicción posterior evidenciamos que los datos observados de incidencia de rotavirus son asimétricos hacia la izquierda (o asimetría positiva).\nUsualmente la transformación que mejor funciona en este caso es el logaritmo natural (de hecho el resto de datos que hemos usado en el curso coincidentalmente han presentado el mismo tipo de asimetría).\n\n\n\n\nlm3 &lt;- lm(log(cases + 1) ~ TXK + UPM, data = rot_berlin)\ncheck_model(lm3)"
  },
  {
    "objectID": "index.html#transformaciones-1",
    "href": "index.html#transformaciones-1",
    "title": "Estadística aplicada con R",
    "section": "Transformaciones",
    "text": "Transformaciones"
  },
  {
    "objectID": "index.html#removiendo-outliers",
    "href": "index.html#removiendo-outliers",
    "title": "Estadística aplicada con R",
    "section": "Removiendo outliers",
    "text": "Removiendo outliers\n\n\nLa distancia de Cook nos ha ayudado a identificar una observación claramente influyente.\nPara continuar, removeremos esa observación para ver que tanto ayuda a nuestro análisis.\n\n\n\n\nrot_berlin_out &lt;- rot_berlin[-22, ]\nlm4 &lt;- lm(log(cases + 1) ~ TXK + UPM, data = rot_berlin_out)\ncheck_model(lm4)"
  },
  {
    "objectID": "index.html#removiendo-outliers-1",
    "href": "index.html#removiendo-outliers-1",
    "title": "Estadística aplicada con R",
    "section": "Removiendo outliers",
    "text": "Removiendo outliers"
  },
  {
    "objectID": "index.html#modelo-final",
    "href": "index.html#modelo-final",
    "title": "Estadística aplicada con R",
    "section": "Modelo final",
    "text": "Modelo final\n\n\nUna vez que hemos llegado a nuestro modelo, revisamos los resultads (este paso lo pudimos hacer en cada paso)\n\n\n\n\nsummary(lm4)\n\n\nCall:\nlm(formula = log(cases + 1) ~ TXK + UPM, data = rot_berlin_out)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.56135 -0.25645 -0.01463  0.23747  0.89716 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 15.115325   0.785118   19.25   &lt;2e-16 ***\nTXK         -0.156583   0.009426  -16.61   &lt;2e-16 ***\nUPM         -0.126306   0.008891  -14.21   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4208 on 61 degrees of freedom\nMultiple R-squared:  0.8241,    Adjusted R-squared:  0.8184 \nF-statistic: 142.9 on 2 and 61 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "index.html#interpretación",
    "href": "index.html#interpretación",
    "title": "Estadística aplicada con R",
    "section": "Interpretación",
    "text": "Interpretación\n\n\n\n\nCall:\nlm(formula = log(cases + 1) ~ TXK + UPM, data = rot_berlin_out)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.56135 -0.25645 -0.01463  0.23747  0.89716 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 15.115325   0.785118   19.25   &lt;2e-16 ***\nTXK         -0.156583   0.009426  -16.61   &lt;2e-16 ***\nUPM         -0.126306   0.008891  -14.21   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4208 on 61 degrees of freedom\nMultiple R-squared:  0.8241,    Adjusted R-squared:  0.8184 \nF-statistic: 142.9 on 2 and 61 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nHaremos uso nuevamente de la librería ggeffects para lidiar con la retransformación y ggplot2 junto a patchwork para graficar las predicciones.\n\n\nlibrary(ggeffects)\nlibrary(ggplot2)\nlibrary(patchwork)\npredicciones &lt;- ggpredict(lm4)\npredicciones[[1]]\n\n# Predicted values of cases\n\nTXK | Predicted |           95% CI\n----------------------------------\n  0 |    243.15 | [180.49, 327.44]\n  5 |    110.59 | [ 89.35, 136.83]\n 10 |     50.01 | [ 43.45,  57.53]\n 15 |     22.31 | [ 19.98,  24.90]\n 20 |      9.66 | [  8.22,  11.32]\n 25 |      3.87 | [  2.91,   5.07]\n 30 |      1.23 | [  0.64,   2.03]\n\nAdjusted for:\n* UPM = 76.14\n\n\n\n\n\npredicciones[[2]]\n\n# Predicted values of cases\n\nUPM | Predicted |           95% CI\n----------------------------------\n 60 |    186.40 | [137.04, 253.40]\n 65 |     98.65 | [ 78.63, 123.71]\n 70 |     51.99 | [ 44.54,  60.67]\n 75 |     27.18 | [ 24.32,  30.37]\n 80 |     13.99 | [ 12.22,  15.99]\n 85 |      6.97 | [  5.59,   8.63]\n 90 |      3.24 | [  2.24,   4.54]\n 95 |      1.25 | [  0.59,   2.20]\n\nAdjusted for:\n* TXK = 14.71\n\n\n\n\n\np1 &lt;- predicciones[[1]]\np2 &lt;- predicciones[[2]]\nplot(p1) + plot(p2)"
  },
  {
    "objectID": "index.html#ejercicio-5.1",
    "href": "index.html#ejercicio-5.1",
    "title": "Estadística aplicada con R",
    "section": "Ejercicio 5.1",
    "text": "Ejercicio 5.1\n\nRealiza un modelo de regresión lineal múltiple para los mismos datos que acabas de ver siguiendo tu propia iniciativa:\n\nPuedes cambiar el orden de los pasos que sugerí\nRealizar chequeos de la significancia de los coeficientes de los modelos candidatos entre paso y paso (cosa que yo no hice)\nPuedes llevar a cabo una selección de variables manual, o cambiar el argumento direction de la función step por “forward” o “backward”"
  },
  {
    "objectID": "index.html#sobre-el-r2-de-nuevo",
    "href": "index.html#sobre-el-r2-de-nuevo",
    "title": "Estadística aplicada con R",
    "section": "Sobre el \\(R^2\\) de nuevo",
    "text": "Sobre el \\(R^2\\) de nuevo\n\n\nComo mencioné al final del anterior módulo, el coeficiente de determinación es una métrica mal usada.\nMediante la función compare_performance de la librería performance, se puede obtener un gráfico de telarañas que permite ver como el \\(R^2\\) no sirve de nada ante modelos mejor formulados.\nAhora recordemos que al final eliminamos un outlier con el modelo que mejores diagnósticos terminamos. Para poner a todos los modelos candidatos en igualdad de condiciones, los corremos de nuevo sin ese outlier (además de utilizar una variable previamente transformada para los modelos 3 y 4, ya que performance no es capaz de retransformar por si solo)\n\n\n\n\nrot_berlin$cases_comp &lt;- rot_berlin$cases + 1\nrot_berlin_out$cases_comp &lt;- rot_berlin_out$cases + 1\nlm1.1 &lt;- lm(cases ~ FM + RSK + SHK_TAG + PM + TMK + TXK + TNK + UPM, data = rot_berlin_out)\nlm2.1 &lt;- lm(cases ~ TXK + UPM, data = rot_berlin_out)\nlm3.1 &lt;- lm(log(cases_comp) ~ TXK + UPM, data = rot_berlin_out)\nlm4.1 &lt;- lm(log(cases_comp) ~ TXK + UPM, data = rot_berlin_out)\n\ncompare_performance(lm1.1, lm2.1, lm3.1, lm4.1, rank = T)\n\n# Comparison of Model Performance Indices\n\nName  | Model |    R2 | R2 (adj.) |   RMSE |  Sigma | AIC weights | AICc weights | BIC weights | Performance-Score\n------------------------------------------------------------------------------------------------------------------\nlm3.1 |    lm | 0.824 |     0.818 |  0.411 |  0.421 |       0.500 |        0.500 |       0.500 |            94.93%\nlm4.1 |    lm | 0.824 |     0.818 |  0.411 |  0.421 |       0.500 |        0.500 |       0.500 |            94.93%\nlm1.1 |    lm | 0.847 |     0.825 | 12.989 | 14.011 |    7.53e-11 |     1.33e-11 |    1.16e-13 |            33.96%\nlm2.1 |    lm | 0.759 |     0.751 | 16.341 | 16.738 |    1.26e-14 |     1.26e-14 |    1.26e-14 |             0.00%\n\n\n\n\n\nplot(compare_performance(lm1.1, lm2.1, lm3.1, lm4.1))"
  },
  {
    "objectID": "index.html#sobre-el-r2-de-nuevo-1",
    "href": "index.html#sobre-el-r2-de-nuevo-1",
    "title": "Estadística aplicada con R",
    "section": "Sobre el \\(R^2\\) de nuevo",
    "text": "Sobre el \\(R^2\\) de nuevo\n\n\nSolo para tener una idea, ya que no vimos los diagnósticos del modelo que según el \\(R^2\\) sería el mejor, démosles un vistazo ahora\n\n\n\n\ncheck_model(lm1.1)"
  },
  {
    "objectID": "index.html#qué-son-los-modelos-lineales-generalizados",
    "href": "index.html#qué-son-los-modelos-lineales-generalizados",
    "title": "Estadística aplicada con R",
    "section": "¿Qué son los modelos lineales generalizados?",
    "text": "¿Qué son los modelos lineales generalizados?\n\n\nEn breve, los modelos lineales generalizados son aquellos que no consideran normalmente distribuida a la variable de interés.\nToman este nombre ya que generalizan la regresión lineal al permitirle relacionarse con la variable de respuesta a través de una función de enlace que transforma a esta última a la escala normal.\nPor tanto, estos modelos también compartirán los supuestos de la homogeneidad de la varianza y normalidad de los residuos. Aunque dependiendo de cada función de enlace a usarse, habrán otros estadísticos de interés.\nSon especialmente útiles en casos como los que mencioné durante los “pasas para realizar un estudio” donde remarcamos la importancia de tener en mente si la variable de respuesta a medir puede o no ser modelada bajo el paradigma normal.\nEn vista de lo basta que es la metodología dentro de este apartado de la estadística, nos enfocaremos en tan solo dos ejemplos:\n\nLa regresión de Poisson\nLa regresión binomial negativa"
  },
  {
    "objectID": "index.html#regresión-de-poisson-en-r",
    "href": "index.html#regresión-de-poisson-en-r",
    "title": "Estadística aplicada con R",
    "section": "Regresión de Poisson en R",
    "text": "Regresión de Poisson en R\n\n\nEn breve, la regresión de Poisson se usa para el modelado de datos discretos que representan el conteo de algún evento.\nEn el ejemplo que consideramos anteriormente, el número de casos de rotavirus es un ejemplo de este tipo de eventos.\nLa razón por la que ese modelo funcionó relativamente bien es porque inadvertidamente impusimos la función de enlace sobre los datos al aplicar la transformación logarítmica.\nVeamos que sucede al implementarla en R\n\n\n\n\nglm1 &lt;- glm(cases ~ TXK + UPM, data = rot_berlin_out, family = \"poisson\")\ncheck_model(glm1)"
  },
  {
    "objectID": "index.html#regresión-de-poisson-en-r-1",
    "href": "index.html#regresión-de-poisson-en-r-1",
    "title": "Estadística aplicada con R",
    "section": "Regresión de Poisson en R",
    "text": "Regresión de Poisson en R"
  },
  {
    "objectID": "index.html#regresión-binomial-negativa",
    "href": "index.html#regresión-binomial-negativa",
    "title": "Estadística aplicada con R",
    "section": "Regresión binomial negativa",
    "text": "Regresión binomial negativa\n\n\nVemos que el modelo usando la regresión de Poisson no mejora mucho en términos de los supuestos.\nComo mencionamos, el gráfico de sobredispersión ya nos da un indicativo de que el modelo es incorrecto.\nUna alternativa para lidiar con sobredispersión es usar la regresión binomial negativa\nPara ello, usaremos la librería MASS que ofrece esta funcionalidad\n\n\n\n\nlibrary(MASS)\nglm2 &lt;- glm.nb(cases ~ TXK + UPM, data = rot_berlin_out)\ncheck_model(glm2)"
  },
  {
    "objectID": "index.html#regresión-binomial-negativa-1",
    "href": "index.html#regresión-binomial-negativa-1",
    "title": "Estadística aplicada con R",
    "section": "Regresión binomial negativa",
    "text": "Regresión binomial negativa"
  },
  {
    "objectID": "index.html#comparación-de-modelos",
    "href": "index.html#comparación-de-modelos",
    "title": "Estadística aplicada con R",
    "section": "Comparación de modelos",
    "text": "Comparación de modelos\n\n\nComparemos primero todos los modelos que hemos llevado a cabo hasta aquí sin rankearlos\n\n\n\n\nlibrary(flextable)\ncolformat_double(flextable(compare_performance(lm1.1, lm2.1, lm4.1, glm1, glm2)), digits = 3)\n\n\nNameModelAICAIC_wtAICcAICc_wtBICBIC_wtRMSESigmaR2_NagelkerkeScore_logScore_sphericalR2R2_adjustedlm1.1lm529.8250.000533.9760.000551.4140.00012.98914.0110.8470.825lm2.1lm547.2120.000547.8900.000555.8480.00016.34116.7380.7590.751lm4.1lm484.5910.112485.2690.112493.2270.1120.4110.4210.8240.818glm1glm681.4630.000681.8630.000687.9390.00017.4262.4231.000-5.2770.090glm2negbin480.4400.888481.1180.888489.0760.88820.8761.0290.995-3.8450.101"
  },
  {
    "objectID": "index.html#jasp",
    "href": "index.html#jasp",
    "title": "Estadística aplicada con R",
    "section": "JASP",
    "text": "JASP"
  },
  {
    "objectID": "index.html#comparación-de-modelos-1",
    "href": "index.html#comparación-de-modelos-1",
    "title": "Estadística aplicada con R",
    "section": "Comparación de modelos",
    "text": "Comparación de modelos\n\n\nAhora rankeados\n\n\n\n\ncolformat_double(flextable(compare_performance(lm1.1, lm2.1, lm4.1, glm1, glm2, rank = T)), digits = 3)\n\n\nNameModelRMSESigmaR2_NagelkerkeScore_logScore_sphericalR2R2_adjustedAIC_wtAICc_wtBIC_wtPerformance_Scoreglm2negbin20.8761.0290.995-3.8450.1010.8880.8880.8880.793lm4.1lm0.4110.4210.8240.8180.1120.1120.1120.475glm1glm17.4262.4231.000-5.2770.0900.0000.0000.0000.209lm1.1lm12.98914.0110.8470.8250.0000.0000.0000.111lm2.1lm16.34116.7380.7590.7510.0000.0000.0000.044"
  },
  {
    "objectID": "index.html#consideraciones-sobre-la-comparación-de-modelos",
    "href": "index.html#consideraciones-sobre-la-comparación-de-modelos",
    "title": "Estadística aplicada con R",
    "section": "Consideraciones sobre la comparación de modelos",
    "text": "Consideraciones sobre la comparación de modelos\n\n\nLa versatilidad de performance es que nos permite comparar entre modelos provenientes de distintas metodologías estadísticas (hace no más de 5 años eso no era posible).\nSin embargo, hay que tener en cuenta que para que las comparaciones sean válidas, los modelos tienen que haber sido ajustados sobre los mismos datos.\nPor ejemplo, no hubiese sido correcto en este ejemplo comparar todos los modelos que llevamos a cabo sin que estos hubiesen sido ajustados sobre la tabla de datos sin el outlier."
  },
  {
    "objectID": "index.html#ejercicio-5.2",
    "href": "index.html#ejercicio-5.2",
    "title": "Estadística aplicada con R",
    "section": "Ejercicio 5.2",
    "text": "Ejercicio 5.2\n\nAnteriormente mencionamos que los datos del rotavirus tienen una característica temporal. A partir de los modelos que mejor desempeño mostraron, trata de agregar un efecto temporal ya sea con los meses o las semanas epidemiológicas. ¿Qué notas de extraño en los resultados?"
  },
  {
    "objectID": "index.html#jasp-1",
    "href": "index.html#jasp-1",
    "title": "Estadística aplicada con R",
    "section": "JASP",
    "text": "JASP\n\n\nJASP es un software estadístico de licencia libre desarrollado por la Universidad de Amsterdam.\nTiene un funcionamiento similar a SPSS con la diferencia de que realiza los análisis en tiempo real sin necesidad de un botón de ejecución.\nEsta basado en R y presenta la alternativa de llevar a cabo también metodologías Bayesianas de una manera simple.\nEs una buena alternativa para análisis estadísticos sencillos mediante una interface amigable e intuitiva.\nDesventajas: no tenemos la libertad de realizar muchos más análisis como en R, todavía se encuentra en etapas tempranas de desarrollo y tiende a presentar aún varios bugs y no es aún confiable para análisis muy complejos."
  }
]